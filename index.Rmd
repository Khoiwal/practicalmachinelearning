---
title: "Prediction Assignment Writeup"
author: "Daniel Frederico Lins Leite"
date: "4 February 2017"
output: md_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret); library(rattle); library(rpart); library(rpart.plot)
library(randomForest); library(repmis);require(corrplot)
```

# Prediction Assignment
## Background 

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

## Preparing the data

### Downloading and loading data

```{r cars}
download.file('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv','pml-training.csv' )
download.file('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv','pml-testing.csv')

training <- read.csv('pml-training.csv',
                     header = TRUE,
                     sep = ",",
                     na.strings = c("NA", "#DIV/0!"))

testing <- read.csv('pml-testing.csv',
                     header = TRUE,
                     sep = ",",
                     na.strings = c("NA", "#DIV/0!"))
```

### Choosing Columns

The first step is to limit our analysis to the variables that are related with the sensors. Initially we have 153 variables and the output variable "classe".

```{r}
sensorColumns <- grepl("classe|belt|arm|dumbell", names(training))
training <- training[,sensorColumns]
testing <- testing[,sensorColumns]
```

All columns that have at leat one NA/null, have more than 97% of NA/null values. In this case it does not make any sense to try to "guess", or round the missing values. Thus, we will remove these columns from the data frame.

```{r}
unique(colSums(is.na(training)) / nrow(training))
cols.without.na = colSums(is.na(training)) == 0
training <- training[, cols.without.na]
```

All chosen variables also pass the nearZeroVar test. 

```{r}
nearZeroVar(training, saveMetrics = TRUE)
```

Ideally we should have a lot of uncorrelated variables. The following graph show that the correlation level is not so high, so we can, indeed, proceed with the chosen set of variables, we do NOT need to do a feature extraction with PCA, for example.

```{r}
corrplot.mixed(cor(training[,c(1:39)]), lower="circle", upper="color", 
               tl.pos="lt", diag="n", order="hclust",
               hclust.method="complete")
```

## Prediction Model
### Classification Tree

To create and avaliate the Classification Tree we will use a 70-30 split of the training model. This will allows us to calculate the out-of-the-sample accuracy of the model before we test the model on "real" data.

The model is created used the caret package with the random forest method with 5-k fold cross validation.

```{r}
set.seed(8256)

inTraining <- createDataPartition(training$classe, p=0.7, list=F)
trainingTr <- training[inTraining,]
trainingTe <- training[-inTraining,]

# Enable Parallel processing
library(parallel)
library(doParallel)
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

control <- trainControl(method = "cv", number = 5, allowParallel = TRUE)
rfModel <- train(classe ~ ., data = trainingTr, method = "rf", trControl = control)

# Disable Parallel processing
stopCluster(cluster)
registerDoSEQ()
```

### Analysis of the Model

```{r}
print(rfModel, digits = 4)
```

```{r}
pred <- predict(rfModel, newdata = trainingTe)
ootsAccuracy <- sum(pred == trainingTe$classe) / length(pred)
confusionMatrix(trainingTe$classe, pred)$table
```

The chosen model have in-the-sample accuracy of `r max(rfModel$results$Accuracy)` and out-of-the-sample accuracy of `r ootsAccuracy`

In this case the 20 most important variables of the model are:
```{r}
varImp(rfModel)
```

# Final Prediction

Using the chosen model in the test dataset we arrive have the following 20 predictions:

```{r}
pred <- predict(rfModel, newdata = testing)
print(pred)
```